{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4612e9-3e40-442d-9633-125ca0a2fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d623f67-d28f-4308-90aa-90075b4fcd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = r'input your keyword file here'\n",
    "\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    # Read each line in the csv file\n",
    "    contents = file.readlines()\n",
    "    print(contents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c2e8f-fd57-4b8f-bd06-bfeae6e39097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each row to add quotes\n",
    "processed_rows = []\n",
    "\n",
    "for row in contents:\n",
    "    # Split the row by delimiter, default is comma (,)\n",
    "    words = row.strip().split(';')\n",
    "\n",
    "    # Process each quotes to add quotes and commas\n",
    "    processed_row = ', '.join([f'\"{word.strip().lower()}\"' for word in words])\n",
    "\n",
    "    processed_rows.append(processed_row)\n",
    "\n",
    "print(processed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22722b51-9b2f-416d-819b-a1d690637d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Set Oxylabs proxy credentials\n",
    "username = 'input proxy username'  # Replace with your username\n",
    "password = 'input proxy password'        # Replace with your password\n",
    "\n",
    "# Create proxy URL\n",
    "proxy_entry = f'http://customer-{username}:{password}@pr.oxylabs.io:7777'\n",
    "\n",
    "# Configure the ProxyHandler\n",
    "proxy_handler = urllib.request.ProxyHandler({\n",
    "    'http': proxy_entry,\n",
    "    'https': proxy_entry,\n",
    "})\n",
    "\n",
    "# Build an opener using the proxy handler\n",
    "opener = urllib.request.build_opener(proxy_handler)\n",
    "\n",
    "# Test the proxy\n",
    "try:\n",
    "    print(\"Testing proxy...\")\n",
    "    response = opener.open('https://ip.oxylabs.io/location', timeout=10)\n",
    "    print(response.read().decode('utf-8'))\n",
    "except urllib.error.URLError as e:\n",
    "    print(f\"URL Error: {e.reason}\")\n",
    "except urllib.error.HTTPError as e:\n",
    "    print(f\"HTTP Error: {e.code} - {e.reason}\")\n",
    "except Exception as e:\n",
    "    print(f\"General Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bed1b6-2c38-414e-b4a8-0ca5fcc89e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords =     [\"paste all keywords from above cells\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ba276-7ba3-4e1e-91b5-edeb1d6e9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import urllib.request\n",
    "\n",
    "# Proxy configuration\n",
    "proxies = {\n",
    "    \"https\": \"input your proxy url\"\n",
    "}\n",
    "\n",
    "# Create proxy URL\n",
    "proxy_entry = f'input your proxy url'\n",
    "\n",
    "# Configure the ProxyHandler\n",
    "proxy_handler = urllib.request.ProxyHandler({\n",
    "    'http': proxy_entry,\n",
    "    'https': proxy_entry,\n",
    "})\n",
    "\n",
    "# Build an opener using the proxy handler\n",
    "opener = urllib.request.build_opener(proxy_handler)\n",
    "\n",
    "print(\"Testing proxy...\")\n",
    "response = opener.open('https://ip.oxylabs.io/location', timeout=10)\n",
    "print(response.read().decode('utf-8'))\n",
    "\n",
    "\n",
    "# Create a global session with the proxy\n",
    "session = requests.Session()\n",
    "session.proxies.update(proxies)\n",
    "\n",
    "# Output directory\n",
    "output_dir = r'US_data'                       #C:\\Users\\em18921\\Documents\\Sentinels_indicator\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to split keywords into smaller batches\n",
    "def split_keywords(keywords, batch_size=5):  # Limit to 1 keyword per batch\n",
    "    for i in range(0, len(keywords), batch_size):\n",
    "        yield keywords[i:i + batch_size]\n",
    "\n",
    "batches = list(split_keywords(keywords))\n",
    "\n",
    "# Function to generate yearly timeframes\n",
    "def generate_timeframes(start_year, end_year):\n",
    "    timeframes = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        start_date = f\"{year}-01-01\"\n",
    "        end_date = f\"{year}-12-31\" #if year < end_year else datetime.now().strftime('%Y-%m-%d')\n",
    "        timeframes.append(f\"{start_date} {end_date}\")\n",
    "    return timeframes\n",
    "\n",
    "timeframes = generate_timeframes(2004, 2019)\n",
    "\n",
    "# Start processing\n",
    "for idx, batch in enumerate(batches):\n",
    "    for timeframe in timeframes:\n",
    "        for attempt in range(3):  # Retry up to 3 times\n",
    "            try:\n",
    "                print(f\"{timeframe}_batch_{idx + 1} | Timeframe: {timeframe}\")\n",
    "                    \n",
    "                # Initialize Pytrends with the custom session\n",
    "                pytrends = TrendReq(requests_args={'headers': {'User-Agent': 'Mozilla/5.0'}})\n",
    "                pytrends.requests = session  # Use the session with proxies\n",
    "    \n",
    "                # Build payload with current batch and timeframe\n",
    "                pytrends.build_payload(batch, timeframe=timeframe, geo='US')\n",
    "                df = pytrends.interest_over_time()\n",
    "    \n",
    "                if not df.empty:\n",
    "                    # Save results to CSV with unique filename\n",
    "                    output_file_path = os.path.join(\n",
    "                        output_dir, f\"{timeframe}_US_batch_{idx + 1}.csv\"\n",
    "                    )\n",
    "                    df.to_csv(output_file_path, index=True)\n",
    "                    print(f\"{timeframe}_batch_{idx + 1} | Timeframe {timeframe} data saved to {output_file_path}\")\n",
    "                else:\n",
    "                    print(f\"No data for {timeframe}_batch_{idx + 1} | Timeframe {timeframe}\")\n",
    "    \n",
    "                # Add a random delay between requests (5–10 minutes)\n",
    "                delay = random.randint(30, 70)  # 5 to 10 minutes\n",
    "                print(f\"Waiting {delay} seconds before next request...\")\n",
    "                time.sleep(delay)\n",
    "    \n",
    "                break  # Exit retry loop on success\n",
    "    \n",
    "            except Exception as e:\n",
    "                print(f\"Error for au_batch_{idx + 2} | Timeframe {timeframe} | Attempt {attempt + 3}: {e}\")\n",
    "                traceback.print_exc()\n",
    "                wait_time = 1.123 ** attempt * 60  # Exponential backoff (1, 2, 4 minutes)\n",
    "                print(f\"Waiting {wait_time} seconds before retrying...\")\n",
    "                time.sleep(wait_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e2b81d-32f0-45b2-930a-23c28d377783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import urllib.request\n",
    "\n",
    "# Proxy configuration\n",
    "proxies = {\n",
    "    \"https\": \"input your proxy url\"\n",
    "}\n",
    "\n",
    "# Create proxy URL\n",
    "proxy_entry = f'input your proxy url'\n",
    "\n",
    "# Configure the ProxyHandler\n",
    "proxy_handler = urllib.request.ProxyHandler({\n",
    "    'http': proxy_entry,\n",
    "    'https': proxy_entry,\n",
    "})\n",
    "\n",
    "# Build an opener using the proxy handler\n",
    "opener = urllib.request.build_opener(proxy_handler)\n",
    "\n",
    "print(\"Testing proxy...\")\n",
    "response = opener.open('https://ip.oxylabs.io/location', timeout=10)\n",
    "print(response.read().decode('utf-8'))\n",
    "\n",
    "\n",
    "# Create a global session with the proxy\n",
    "session = requests.Session()\n",
    "session.proxies.update(proxies)\n",
    "# Output directory\n",
    "output_dir = r'US_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to split keywords into smaller batches\n",
    "def split_keywords(keywords, batch_size=5):  # Limit to 1 keyword per batch\n",
    "    for i in range(0, len(keywords), batch_size):\n",
    "        yield keywords[i:i + batch_size]\n",
    "\n",
    "batches = list(split_keywords(keywords))\n",
    "\n",
    "# Function to generate yearly timeframes\n",
    "#def generate_timeframes(start_year, end_year):\n",
    "    #timeframes = []\n",
    "    #for year in range(start_year, end_year + 1):\n",
    "        #start_date = f\"{year}-01-01\"\n",
    "        #end_date = f\"{year}-12-31\" #if year < end_year else datetime.now().strftime('%Y-%m-%d')\n",
    "        #timeframes.append(f\"{start_date} {end_date}\")\n",
    "    #return timeframes\n",
    "\n",
    "timeframes = 'today 5-y'\n",
    "\n",
    "# Start processing\n",
    "for idx, batch in enumerate(batches):\n",
    "    #for timeframe in timeframes:\n",
    "    for attempt in range(3):  # Retry up to 3 times\n",
    "        try:\n",
    "            print(f\"{timeframes}_batch_{idx + 1} | Timeframe: {timeframes}\")\n",
    "                \n",
    "            # Initialize Pytrends with the custom session\n",
    "            pytrends = TrendReq(requests_args={'headers': {'User-Agent': 'Mozilla/5.0'}})\n",
    "            pytrends.requests = session  # Use the session with proxies\n",
    "\n",
    "            # Build payload with current batch and timeframe\n",
    "            pytrends.build_payload(batch, timeframe=timeframes, geo='US')\n",
    "            df = pytrends.interest_over_time()\n",
    "\n",
    "            if not df.empty:\n",
    "                # Save results to CSV with unique filename\n",
    "                output_file_path = os.path.join(\n",
    "                    output_dir, f\"{timeframes}_US_batch_{idx + 1}.csv\"\n",
    "                )\n",
    "                df.to_csv(output_file_path, index=True)\n",
    "                print(f\"{timeframes}_batch_{idx + 1} | Timeframe {timeframes} data saved to {output_file_path}\")\n",
    "            else:\n",
    "                print(f\"No data for {timeframes}_batch_{idx + 1} | Timeframe {timeframes}\")\n",
    "\n",
    "            # Add a random delay between requests (5–10 minutes)\n",
    "            delay = random.randint(30, 70)  # 5 to 10 minutes\n",
    "            print(f\"Waiting {delay} seconds before next request...\")\n",
    "            time.sleep(delay)\n",
    "\n",
    "            break  # Exit retry loop on success\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error for 24_Nov_batch_{idx + 1} | Timeframe {timeframes} | Attempt {attempt + 3}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            wait_time = 1 ** attempt * 60  # Exponential backoff (1, 2, 4 minutes)\n",
    "            print(f\"Waiting {wait_time} seconds before retrying...\")\n",
    "            time.sleep(wait_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b4cc7-1782-4aa0-8123-75f728e970b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3eae5e-4c4a-4123-9e93-3b8d6f8cdf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
